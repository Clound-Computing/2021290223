{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('content_truth.json', 'r',encoding='utf-8') as f:\n",
    "    data_origin = json.load(f)\n",
    "\n",
    "content_truth=pd.DataFrame(data_origin)\n",
    "\n",
    "with open('content_rumor.json', 'r',encoding='utf-8') as f:\n",
    "    data_origin = json.load(f)\n",
    "\n",
    "content_rumor=pd.DataFrame(data_origin)\n",
    "\n",
    "with open('story.json', 'r',encoding='utf-8') as f:\n",
    "    data_origin = json.load(f)\n",
    "\n",
    "df_story=pd.DataFrame(data_origin)\n",
    "\n",
    "with open('style1.json', 'r',encoding='utf-8') as f:\n",
    "    data_origin = json.load(f)\n",
    "\n",
    "df_style1=pd.DataFrame(data_origin)\n",
    "\n",
    "with open('style2.json', 'r',encoding='utf-8') as f:\n",
    "    data_origin = json.load(f)\n",
    "\n",
    "df_style2=pd.DataFrame(data_origin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7771, 15)\n",
      "(7771, 15)\n",
      "(10631, 15)\n",
      "(10795, 16)\n",
      "(7774, 15)\n"
     ]
    }
   ],
   "source": [
    "print(content_truth.shape)\n",
    "print(content_rumor.shape)\n",
    "print(df_story.shape)\n",
    "print(df_style1.shape)\n",
    "print(df_style2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = int(content_truth.shape[0])\n",
    "content_truth_train = content_truth.loc[0:int(width*0.5),:].copy().reset_index(drop=True)\n",
    "content_truth_val = content_truth.loc[int(width*0.5):int(width*0.7),:].copy().reset_index(drop=True)\n",
    "content_truth_test = content_truth.loc[int(width*0.7):,:].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = content_rumor.shape[0]\n",
    "content_rumor_train = content_rumor.loc[0:int(width*0.5),:].copy().reset_index(drop=True)\n",
    "content_rumor_val = content_rumor.loc[int(width*0.5):int(width*0.7),:].copy().reset_index(drop=True)\n",
    "content_rumor_test = content_rumor.loc[int(width*0.7):,:].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = df_story.shape[0]\n",
    "df_story_train = df_story.loc[0:int(width*0.5),:].copy().reset_index(drop=True)\n",
    "df_story_val = df_story.loc[int(width*0.5):int(width*0.7),:].copy().reset_index(drop=True)\n",
    "df_story_test = df_story.loc[int(width*0.7):,:].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = df_style1.shape[0]\n",
    "df_style1_train = df_style1.loc[0:int(width*0.5),:].copy().reset_index(drop=True)\n",
    "df_style1_val = df_style1.loc[int(width*0.5):int(width*0.7),:].copy().reset_index(drop=True)\n",
    "df_style1_test = df_style1.loc[int(width*0.7):,:].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = df_style2.shape[0]\n",
    "df_style2_train = df_style2.loc[0:int(width*0.5),:].copy().reset_index(drop=True)\n",
    "df_style2_val = df_style2.loc[int(width*0.5):int(width*0.7),:].copy().reset_index(drop=True)\n",
    "df_style2_test = df_style2.loc[int(width*0.7):,:].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all=pd.concat([content_truth_train,content_rumor_train, df_story_train ,df_style1_train,df_style2_train  ], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "val_all=pd.concat([content_truth_val,content_rumor_val, df_story_val ,df_style1_val,df_style2_val  ], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "test_all = pd.concat([content_truth_test,content_rumor_test, df_story_test ,df_style1_test,df_style2_test  ], axis=0, ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_drop=['origin_title','generated_tone','generated_label']\n",
    "train_all=train_all.drop(columns=columns_drop)\n",
    "val_all=val_all.drop(columns=columns_drop)\n",
    "test_all=test_all.drop(columns=columns_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all=train_all.rename(columns={'origin_id':'id'})\n",
    "val_all=val_all.rename(columns={'origin_id':'id'})\n",
    "test_all=test_all.rename(columns={'origin_id':'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def to_num_id(str_example):\n",
    "    numbers = re.findall(r'\\d+', str_example)\n",
    "    if numbers:\n",
    "        number_as_int = int(numbers[0])\n",
    "    return number_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id=train_all['id'].to_list()\n",
    "id_list=[to_num_id(i) for i in train_id]\n",
    "train_all['id']=id_list\n",
    "\n",
    "val_id=val_all['id'].to_list()\n",
    "id_list=[to_num_id(i) for i in val_id]\n",
    "val_all['id']=id_list\n",
    "\n",
    "test_id=test_all['id'].to_list()\n",
    "id_list=[to_num_id(i) for i in test_id]\n",
    "test_all['id']=id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all=train_all[train_all['year']>2005].reset_index(drop=True)\n",
    "val_all=val_all[val_all['year']>2005].reset_index(drop=True)\n",
    "test_all=test_all[test_all['year']>2005].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = train_all.to_dict(orient='records')\n",
    "file_path = 'train_all.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = val_all.to_dict(orient='records')\n",
    "file_path = 'val_all.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = test_all.to_dict(orient='records')\n",
    "file_path = 'test_all.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "season1_train = train_all[train_all['season']==1].copy().reset_index(drop=True)\n",
    "season2_train = train_all[train_all['season']==2].copy().reset_index(drop=True)\n",
    "season3_train = train_all[train_all['season']==3].copy().reset_index(drop=True)\n",
    "season4_train = train_all[train_all['season']==4].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = season1_train.to_dict(orient='records')\n",
    "file_path = 'season_1/train.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "records = season2_train.to_dict(orient='records')\n",
    "file_path = 'season_2/train.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "records = season3_train.to_dict(orient='records')\n",
    "file_path = 'season_3/train.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "records = season4_train.to_dict(orient='records')\n",
    "file_path = 'season_4/train.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "season1_val = val_all[val_all['season']==1].copy().reset_index(drop=True)\n",
    "season2_val = val_all[val_all['season']==2].copy().reset_index(drop=True)\n",
    "season3_val = val_all[val_all['season']==3].copy().reset_index(drop=True)\n",
    "season4_val = val_all[val_all['season']==4].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = season1_val.to_dict(orient='records')\n",
    "file_path = 'season_1/val.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "records = season2_val.to_dict(orient='records')\n",
    "file_path = 'season_2/val.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "records = season3_val.to_dict(orient='records')\n",
    "file_path = 'season_3/val.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "records = season4_val.to_dict(orient='records')\n",
    "file_path = 'season_4/val.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "season1_test = test_all[test_all['season']==1].copy().reset_index(drop=True)\n",
    "season2_test = test_all[test_all['season']==2].copy().reset_index(drop=True)\n",
    "season3_test = test_all[test_all['season']==3].copy().reset_index(drop=True)\n",
    "season4_test = test_all[test_all['season']==4].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = season1_test.to_dict(orient='records')\n",
    "file_path = 'season_1/test.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "records = season2_test.to_dict(orient='records')\n",
    "file_path = 'season_2/test.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "records = season3_test.to_dict(orient='records')\n",
    "file_path = 'season_3/test.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "records = season4_test.to_dict(orient='records')\n",
    "file_path = 'season_4/test.json'\n",
    "with open(file_path, 'w',encoding='utf-8') as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
